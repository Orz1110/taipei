{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"VD_LSTM","provenance":[],"authorship_tag":"ABX9TyOM6FJdOC+5gqAjogt406tx"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"pL51FDEswuxb","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, CuDNNLSTM, Dropout, TimeDistributed\n","import warnings\n","from sklearn.metrics import mean_squared_error\n","import os\n","import time\n","tStart = time.time()#計時開始\n","print(tStart)\n","\n","warnings.filterwarnings('ignore')\n","import matplotlib.pyplot as plt\n","# pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","# np.set_printoptions(threshold=np.inf)\n","\n","def normalize(df):\n","    norm = df.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n","    max_x = df.apply(lambda x: max(x))\n","    min_x = df.apply(lambda x: min(x))\n","    return norm, max_x, min_x\n","\n","def train_windows(df, ref_day, predict_day):\n","    X_train, Y_train = [], []\n","    for i in range(df.shape[0]-predict_day-ref_day+1):\n","        X_train.append(np.array(df.iloc[i:i+ref_day, :1]))\n","        Y_train.append(np.array(df.iloc[i+ref_day:i+ref_day+predict_day][\"y\"]))\n","    return np.array(X_train), np.array(Y_train)\n","#\n","def lstm_model(shape):\n","    model = Sequential()\n","    model.add(CuDNNLSTM(256, input_shape=(shape[1], shape[2]), return_sequences=True))\n","    model.add(Dropout(0.2))\n","    model.add(CuDNNLSTM(256, return_sequences=True))\n","    model.add(Dropout(0.2))\n","    # model.add(CuDNNLSTM(32, return_sequences=True))\n","    # model.add(Dropout(0.2))\n","    # model.add(TimeDistributed(Dense(1, activation='linear')))\n","    model.add(Flatten())\n","    model.add(Dense(256, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dropout(0.2))\n","    # model.add(Dense(32, activation='linear'))\n","    # model.add(Dropout(0.2))\n","    model.add(Dense(30, activation='relu'))\n","    model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=['mean_absolute_error'])\n","    model.summary()\n","    return model\n","\n","# VD資料集\n","\n","filepath = \"D:/耿嘉/VD/\"\n","filename = os.listdir(filepath)\n","# print(filename)\n","# pd.set_option('display.max_columns', None)\n","data_VD_all = pd.DataFrame([])\n","\n","for i in range(len(filename)):\n","    data = pd.read_csv(filepath+filename[0])\n","    try:\n","\n","        print(filename[i])\n","        data_VD = pd.read_csv(filepath + filename[i])\n","        data_VD = data_VD[data_VD[\"DEVICEID\"] == \"V4010A0\"]\n","        # print(data_VD)\n","        data_VD_all = pd.concat([data_VD, data_VD_all])\n","        print(data_VD_all)\n","\n","    except:\n","        pass\n","data_VD = data_VD_all\n","data = data_VD_all[['BIGVOLUME', 'CARVOLUME', 'MOTORVOLUME']]\n","# data_VD = pd.read_csv(\"D:/耿嘉/20190101000000_20190102000000.csv\")\n","\n","# point = \"V6121A0\"\n","point = \"V4010A0\"\n","\n","# # data_VD = data_VD[data_VD[\"DEVICEID\"] == point]\n","# data_VD = data_VD[data_VD[\"DEVICEID\"] == point]\n","# print(data_VD)\n","\n","#  不同車道加總\n","data_VD = data_VD.groupby(\"DATETIME2\").sum()\n","print(data_VD)\n","# 資料異常處理(還沒做)\n","data_t = data_VD[[\"BIGVOLUME\", \"CARVOLUME\", \"MOTORVOLUME\"]]\n","data_t[\"sum\"] = data_t.sum(axis=1)\n","data_t['y'] = data_t['sum']\n","data_t = data_t[[\"sum\", \"y\"]]\n","# plt.plot(data_t[\"sum\"].values)\n","# plt.ylabel(\"volumns\")\n","# plt.xlabel(\"min\")\n","# plt.xticks(fontsize=20)\n","# plt.yticks(fontsize=20)\n","# plt.show()\n","print(data_t)\n","\n","\n","\n","# 資料正規化\n","# print(data_t)\n","data_tt, max_norm_data, min_norm_data = normalize(data_t)\n","# print(max_norm_data)\n","# print(min_norm_data)\n","# print(data_tt)\n","\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","data_t = scaler.fit_transform(data_t)\n","# print(data_t)\n","data_t = pd.DataFrame(data_t, columns=[\"sum\", \"y\"])\n","# data_t = scaler.inverse_transform(pd.DataFrame(data_t))\n","# print(data_t)\n","\n","# train_test_split\n","\n","from sklearn.model_selection import train_test_split\n","train, test = train_test_split(data_t, test_size=0.1, shuffle=False)\n","# # print(train)\n","\n","# 資料整理\n","\n","X_train, Y_train = train_windows(train, 120, 30)\n","X_test, Y_test = train_windows(test, 120, 30)\n","# Y_train = pd.DataFrame(Y_train, columns=[\"real\"])\n","print(X_test)\n","print(Y_test)\n","\n","def inverse_normalize(inv_data):\n","    inverse_norm_data = []\n","    for i in range(len(inv_data)):\n","        inverse_norm_data.append(np.array((max_norm_data[0] - min_norm_data[0]) * inv_data[i] + min_norm_data[0]))\n","    # inverse_norm_2 = inv_data.apply(lambda x: (max_norm_data[1] - min_norm_data[1]) * x + min_norm_data[1])\n","    return np.array(inverse_norm_data)\n","\n","def draw(title,x_label,y_label,lable):\n","    plt.title(title)\n","    plt.xlabel(x_label)\n","    plt.ylabel(y_label)\n","    plt.legend(lable)\n","    # plt.show()\n","\n","inverse_norm_train = inverse_normalize(Y_train)\n","\n","inverse_norm_test = inverse_normalize(Y_test)\n","# print(inverse_norm_train)\n","# plt.plot(inverse_norm_1)\n","# plt.show()\n","\n","\n","# ---- model TRAIN----\n","\n","model = lstm_model(X_train.shape)\n","history = model.fit(X_train, Y_train, epochs=20, batch_size=1000, validation_split=0.1)\n","\n","plt.figure(1)\n","plt.subplot(221)\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","lable = ['loss', 'val_loss']\n","draw(point+\"_train\", \"epoch\", \"mse\", lable)\n","plt.legend(lable)\n","\n","# ---- model TEST----\n","\n","# history_test = model.fit(X_test, Y_test, epochs=100, batch_size=50, validation_split=0.1, shuffle=True)\n","# plt.plot(history_test.history['loss'])\n","# plt.plot(history_test.history['val_loss'])\n","# lable = ['loss', 'val_loss']\n","# draw(\"test\", \"epoch\", \"mse\", lable)\n","# plt.legend(lable)\n","\n","# predict = model.predict(X_train)\n","# inverse_norm_train_predict = inverse_normalize(predict)\n","# print(np.around(inverse_norm_train_predict))\n","# mse_train = np.sum((np.around(inverse_norm_train_predict) - inverse_norm_train)**2, axis=1)/len(inverse_norm_train)\n","# print(mse_train)\n","#\n","# lable = [\"time\"]\n","# plt.plot(mse_test)\n","# draw(\"V0111C0_train_mse\", lable[0], \"mse\", lable)\n","\n","predict_tr = model.predict(X_train)\n","predict_tr = inverse_normalize(predict_tr).T\n","real_tr = inverse_norm_train.T\n","\n","predict = model.predict(X_test)\n","predict = inverse_normalize(predict).T\n","real = inverse_norm_test.T\n","tEnd = time.time()#計時結束\n","#列印結果\n","print(\"It cost %f sec\" % (tEnd - tStart))#會自動做近位\n","print(\"預測-------\\n\", predict)\n","# print(\"預測-------\\n\", predict.T)\n","print(\"答案---------\\n\", real)\n","rmse_test = np.sqrt(np.sum((predict - real)**2, axis=1)/len(real))\n","print(\"誤差------\\n\\n\", rmse_test)\n","\n","\n","\n","mse_test = np.sum((predict - real)**2, axis=1)/len(real)\n","print(\"誤差------\\n\\n\", mse_test)\n","# rmse = mean_squared_error(inverse_norm_test, np.around(inverse_norm_train_predict), squared=False)\n","# print(\"誤差------\\n\", rmse)\n","# mse = mean_squared_error(inverse_norm_test, np.around(inverse_norm_train_predict))\n","# print(\"誤差------\\n\", mse)\n","\n","\n","lable = [\"time\"]\n","plt.subplot(222)\n","plt.plot(rmse_test)\n","draw(point+\"_test_rmse\", lable[0], \"rmse\", lable)\n","\n","plt.subplot(223)\n","lable = [\"predict\", \"real\"]\n","print(predict_tr[0])\n","print(real_tr[0])\n","plt.plot(predict_tr[0])\n","plt.plot(real_tr[0])\n","draw(\"train_predict&real\", \"min\", \"volumns\", lable)\n","\n","\n","plt.subplot(224)\n","lable = [\"predict\", \"real\"]\n","print(predict[0])\n","print(real[0])\n","plt.plot(predict[0])\n","plt.plot(real[0])\n","draw(\"test_predict&real\", \"min\", \"volumns\", lable)\n","\n","plt.show()\n","\n","\n","\n","\n","\n","\n","'''\n","\n","# 反正規化-train\n","final_train = pd.DataFrame([])\n","Y_train = pd.DataFrame(Y_train, columns=[\"real\"])\n","final_train[\"real\"] = Y_train[\"real\"]\n","predict = pd.DataFrame(predict, columns=[\"predict\"])\n","final_train[\"predict\"] = predict[\"predict\"]\n","final_train = scaler.inverse_transform(final_train)\n","# print(final_train)\n","#\n","# lable_1 = [\"real\", \"predict\"]\n","# plt.plot(final_train[:, 0])\n","# plt.plot(final_train[:, 1])\n","# plt.legend(lable_1)\n","# plt.title(\"train\")\n","# plt.xlabel(\"time\")\n","# plt.ylabel(\"volumn\")\n","# plt.show()\n","\n","# 反正規化-test\n","\n","predict = model.predict(X_test)\n","final_test = pd.DataFrame([])\n","Y_test = pd.DataFrame(Y_test, columns=[\"real\"])\n","final_test[\"real\"] = Y_test[\"real\"]\n","predict = pd.DataFrame(predict, columns=[\"predict\"])\n","final_test[\"predict\"] = predict[\"predict\"]\n","final_test = scaler.inverse_transform(final_test)\n","print(final_test)\n","\n","\n","# 畫圖\n","\n","plt.figure(1)\n","plt.subplot(211)\n","lable_1 = [\"real\", \"predict\"]\n","plt.plot(final_train[:, 0])\n","plt.plot(final_train[:, 1])\n","plt.legend(lable_1)\n","plt.title(\"train\")\n","plt.xlabel(\"time\")\n","plt.ylabel(\"volumn\")\n","\n","plt.subplot(212)\n","lable_1 = [\"real\", \"predict\"]\n","plt.plot(final_test[:, 0])\n","plt.plot(final_test[:, 1])\n","plt.legend(lable_1)\n","plt.title(\"test\")\n","plt.xlabel(\"time\")\n","plt.ylabel(\"volumn\")\n","\n","plt.show()\n","'''"],"execution_count":0,"outputs":[]}]}